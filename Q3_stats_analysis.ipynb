{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.1.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>age</th>\n",
       "      <th>education_level</th>\n",
       "      <th>walking_speed</th>\n",
       "      <th>insurance_type</th>\n",
       "      <th>visit_cost</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>34.28</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>4.40</td>\n",
       "      <td>Private</td>\n",
       "      <td>53.95</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0001</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>34.51</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>4.19</td>\n",
       "      <td>Private</td>\n",
       "      <td>50.70</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0001</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>34.72</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>4.71</td>\n",
       "      <td>Private</td>\n",
       "      <td>46.20</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0001</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>35.00</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>4.86</td>\n",
       "      <td>Private</td>\n",
       "      <td>56.30</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0001</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>35.21</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>4.50</td>\n",
       "      <td>Private</td>\n",
       "      <td>53.70</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id visit_date    age education_level  walking_speed insurance_type  \\\n",
       "0      P0001 2020-01-23  34.28       Bachelors           4.40        Private   \n",
       "1      P0001 2020-04-16  34.51       Bachelors           4.19        Private   \n",
       "2      P0001 2020-07-03  34.72       Bachelors           4.71        Private   \n",
       "3      P0001 2020-10-15  35.00       Bachelors           4.86        Private   \n",
       "4      P0001 2020-12-29  35.21       Bachelors           4.50        Private   \n",
       "\n",
       "   visit_cost  season  \n",
       "0       53.95  Winter  \n",
       "1       50.70  Spring  \n",
       "2       46.20  Summer  \n",
       "3       56.30    Fall  \n",
       "4       53.70  Winter  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Read the processed CSV file.\n",
    "df = pd.read_csv(\"ms_data.csv\")\n",
    "\n",
    "# Convert visit_date to datetime.\n",
    "df['visit_date'] = pd.to_datetime(df['visit_date'])\n",
    "\n",
    "#  Sort by patient_id and visit_date.\n",
    "df = df.sort_values(by = ['patient_id', 'visit_date'])\n",
    "\n",
    "# Read insurance types from `insurance.lst`.\n",
    "with open('insurance.lst', 'r') as f:\n",
    "    insurance_types = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Randomly assign (but keep consistent per patient_id).\n",
    "unique_patients = df['patient_id'].unique()\n",
    "patient_insurance_map = {patient_id: np.random.choice(insurance_types) for patient_id in unique_patients}\n",
    "df['insurance_type'] = df['patient_id'].map(patient_insurance_map)\n",
    "\n",
    "# Generate visit costs based on insurance type. Different plans have different effects on cost.\n",
    "base_costs = {'Medicare': 100,\n",
    "    'Medicaid': 200,\n",
    "    'Private': 50,\n",
    "    'Other': 500\n",
    "}\n",
    "\n",
    "# Add random variation.\n",
    "variation_factor = 0.2 # 20% variation\n",
    "df['visit_cost'] = df['insurance_type'].map(base_costs) * (1 + np.random.uniform(-variation_factor, variation_factor, len(df))).round(3)\n",
    "\n",
    "# Set appropriate data types.\n",
    "df['patient_id'] = df['patient_id'].astype(str)\n",
    "df['education_level'] = df['education_level'].astype(str)\n",
    "df['insurance_type'] = df['insurance_type'].astype(str)\n",
    "\n",
    "# Spring: March, April, May (months 3, 4, 5)\n",
    "# Summer: June, July, August (months 6, 7, 8)\n",
    "# Fall: September, October, November (months 9, 10, 11)\n",
    "# Winter: December, January, February (months 12, 1, 2)\n",
    "\n",
    "# Add a 'season' column based on the month of the visit_date\n",
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "\n",
    "# Apply the get_season function to the 'visit_date' to categorize the season\n",
    "df['season'] = df['visit_date'].dt.month.apply(get_season)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id                 object\n",
      "visit_date         datetime64[ns]\n",
      "age                       float64\n",
      "education_level            object\n",
      "walking_speed             float64\n",
      "insurance_type             object\n",
      "visit_cost                float64\n",
      "season                     object\n",
      "dtype: object\n",
      "Number of missing values in each column: patient_id         0\n",
      "visit_date         0\n",
      "age                0\n",
      "education_level    0\n",
      "walking_speed      0\n",
      "insurance_type     0\n",
      "visit_cost         0\n",
      "season             0\n",
      "dtype: int64\n",
      "Number of rows with at least one missing value: 0\n"
     ]
    }
   ],
   "source": [
    "df['visit_date'] = pd.to_datetime(df['visit_date'])\n",
    "df['patient_id'] = df['patient_id'].astype(str)\n",
    "df['education_level'] = df['education_level'].astype(str)\n",
    "df['age'] = df['age'].astype(float)\n",
    "df['walking_speed'] = df['walking_speed'].astype(float)\n",
    "df['visit_cost'] = df['visit_cost'].astype(float)\n",
    "df['season'] = df['season'].astype(str)\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"Number of missing values in each column: {df.isnull().sum()}\")\n",
    "print(f\"Number of rows with at least one missing value: {df.isnull().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          walking_speed   R-squared:                       0.807\n",
      "Model:                            OLS   Adj. R-squared:                  0.807\n",
      "Method:                 Least Squares   F-statistic:                 2.059e+04\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:32:41   Log-Likelihood:                -5411.7\n",
      "No. Observations:               15431   AIC:                         1.083e+04\n",
      "Df Residuals:                   15426   BIC:                         1.087e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:              cluster                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            5.5992      0.008    690.553      0.000       5.583       5.615\n",
      "Graduate         0.4152      0.007     59.939      0.000       0.402       0.429\n",
      "High School     -0.7923      0.007   -117.312      0.000      -0.806      -0.779\n",
      "Some College    -0.3903      0.007    -57.322      0.000      -0.404      -0.377\n",
      "age             -0.0301      0.000   -219.260      0.000      -0.030      -0.030\n",
      "==============================================================================\n",
      "Omnibus:                        7.060   Durbin-Watson:                   1.868\n",
      "Prob(Omnibus):                  0.029   Jarque-Bera (JB):                6.668\n",
      "Skew:                           0.023   Prob(JB):                       0.0357\n",
      "Kurtosis:                       2.909   Cond. No.                         238.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "# 1. Analyze walking speed:\n",
    "#    - Multiple regression with education and age (report coeffcients and confidence intervals)\n",
    "#    - Account for repeated measures\n",
    "#    - Test for significant trends\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Prepare the data as before\n",
    "X = df[['age']]\n",
    "X = pd.get_dummies(df['education_level'], drop_first=True).join(X)  # Convert education_level to dummy variables\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "\n",
    "y = df['walking_speed']\n",
    "\n",
    "# Ensure that X and y are purely numeric arrays\n",
    "X = X.astype(float) \n",
    "y = y.astype(float)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Clustered standard errors by subject (assuming 'patient_id' is the subject identifier)\n",
    "clustered_se = model.get_robustcov_results(cov_type='cluster', groups=df['patient_id'])\n",
    "\n",
    "# Display the summary with clustered standard errors\n",
    "print(clustered_se.summary())\n",
    "\n",
    "# Clustered Standard Errors: The cov_type='cluster' argument in get_robustcov_results accounts for the fact that there are repeated measurements for each subject. The groups=df['id'] argument specifies that the clustering should be done by the subject identifier (id).\n",
    "\n",
    "# Interpretation: The coefficients remain the same, but now the standard errors are adjusted for the repeated measurements, which leads to more accurate statistical tests (e.g., p-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.5991894   0.41524264 -0.792317   -0.39032524 -0.03013812]\n",
      "[0.00000e+000 0.00000e+000 0.00000e+000 3.91879e-318 0.00000e+000]\n",
      "[[ 5.5832782   5.61510059]\n",
      " [ 0.40164808  0.4288372 ]\n",
      " [-0.80557048 -0.77906352]\n",
      " [-0.40368752 -0.37696296]\n",
      " [-0.03040785 -0.02986839]]\n",
      "0.8069489306941992\n",
      "0.8069989763375707\n"
     ]
    }
   ],
   "source": [
    "print(clustered_se.params) # Coefficients \n",
    "print(clustered_se.pvalues) # P-values\n",
    "print(clustered_se.conf_int()) # Confidence Intervals\n",
    "print(clustered_se.rsquared_adj)\n",
    "print(clustered_se.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          walking_speed   R-squared:                       0.807\n",
      "Model:                            OLS   Adj. R-squared:                  0.807\n",
      "Method:                 Least Squares   F-statistic:                 1.202e+04\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:32:49   Log-Likelihood:                -5411.6\n",
      "No. Observations:               15431   AIC:                         1.084e+04\n",
      "Df Residuals:                   15423   BIC:                         1.090e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:              cluster                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                5.6021      0.024    233.954      0.000       5.555       5.649\n",
      "Graduate             0.4152      0.007     59.692      0.000       0.402       0.429\n",
      "High School         -0.7952      0.018    -43.039      0.000      -0.831      -0.759\n",
      "Some College        -0.3833      0.018    -20.861      0.000      -0.419      -0.347\n",
      "age                 -0.0303      0.001    -31.590      0.000      -0.032      -0.028\n",
      "age_High School   5.542e-05      0.000      0.166      0.868      -0.001       0.001\n",
      "age_Some College    -0.0001      0.000     -0.409      0.682      -0.001       0.001\n",
      "age_age           1.748e-06   8.94e-06      0.196      0.845   -1.58e-05    1.93e-05\n",
      "==============================================================================\n",
      "Omnibus:                        7.084   Durbin-Watson:                   1.868\n",
      "Prob(Omnibus):                  0.029   Jarque-Bera (JB):                6.692\n",
      "Skew:                           0.023   Prob(JB):                       0.0352\n",
      "Kurtosis:                       2.909   Cond. No.                     3.59e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 3.59e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Test for trends.\n",
    "# You can manually add interaction terms between age and education_level by creating new columns for each level of education (except the reference category). Then, you can include these interaction terms in your model.\n",
    "\n",
    "# Convert 'education_level' into dummy variables\n",
    "X_education = pd.get_dummies(df['education_level'], drop_first=True)\n",
    "\n",
    "# Add 'age' as a predictor\n",
    "X_education = X_education.join(df[['age']])\n",
    "\n",
    "# Create interaction terms between 'age' and each education level\n",
    "for level in X_education.columns[1:]:  # Skip the constant (first column)\n",
    "    X_education[f'age_{level}'] = X_education['age'] * X_education[level]\n",
    "\n",
    "# Add constant term\n",
    "X_education = sm.add_constant(X_education)\n",
    "\n",
    "# Ensure X and y are numeric\n",
    "X_education = X_education.astype(float)\n",
    "\n",
    "# Fit the OLS model\n",
    "model_education = sm.OLS(y, X_education).fit()\n",
    "\n",
    "clustered_se2 = model_education.get_robustcov_results(cov_type='cluster', groups=df['patient_id'])\n",
    "\n",
    "# Display the model summary\n",
    "print(clustered_se2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          walking_speed   R-squared:                       0.512\n",
      "Model:                            OLS   Adj. R-squared:                  0.511\n",
      "Method:                 Least Squares   F-statistic:                     432.0\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):          5.29e-297\n",
      "Time:                        21:32:57   Log-Likelihood:                -12575.\n",
      "No. Observations:               15431   AIC:                         2.517e+04\n",
      "Df Residuals:                   15423   BIC:                         2.523e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.6426      0.121     46.594      0.000       5.405       5.880\n",
      "Spring        -0.2734      0.008    -33.573      0.000      -0.289      -0.257\n",
      "Summer        -0.0692      0.021     -3.225      0.001      -0.111      -0.027\n",
      "Winter        -0.2263      0.022    -10.109      0.000      -0.270      -0.182\n",
      "age           -0.0336      0.005     -6.666      0.000      -0.043      -0.024\n",
      "age_Summer     0.0005      0.000      1.264      0.207      -0.000       0.001\n",
      "age_Winter -9.538e-06      0.000     -0.024      0.981      -0.001       0.001\n",
      "age_age     2.804e-05   4.81e-05      0.583      0.560   -6.63e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      413.077   Durbin-Watson:                   0.730\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              204.292\n",
      "Skew:                           0.016   Prob(JB):                     4.35e-45\n",
      "Kurtosis:                       2.437   Cond. No.                     3.69e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 3.69e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_season = pd.get_dummies(df['season'], drop_first=True)\n",
    "\n",
    "# Add 'age' as a predictor\n",
    "X_season = X_season.join(df[['age']])\n",
    "\n",
    "# Create interaction terms between 'age' and each season\n",
    "for level in X_season.columns[1:]:  # Skip the constant (first column)\n",
    "    X_season[f'age_{level}'] = X_season['age'] * X_season[level]\n",
    "\n",
    "# Add constant term\n",
    "X_season = sm.add_constant(X_season)\n",
    "\n",
    "# Ensure X and y are numeric\n",
    "X_season = X_season.astype(float)\n",
    "\n",
    "# Fit the OLS model\n",
    "model_season = sm.OLS(y, X_season).fit()\n",
    "\n",
    "clustered_se3 = model_season.get_robustcov_results(cov_type='cluster', groups=df['patient_id'])\n",
    "\n",
    "# Display the model summary\n",
    "print(clustered_se3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             visit_cost   R-squared:                       0.967\n",
      "Model:                            OLS   Adj. R-squared:                  0.967\n",
      "Method:                 Least Squares   F-statistic:                 1.509e+05\n",
      "Date:                Tue, 12 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:38:40   Log-Likelihood:                -75903.\n",
      "No. Observations:               15431   AIC:                         1.518e+05\n",
      "Df Residuals:                   15427   BIC:                         1.518e+05\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        198.9878      0.401    496.275      0.000     198.201     199.775\n",
      "Medicare     -99.0659      0.440   -225.291      0.000     -99.929     -98.203\n",
      "Other        300.0318      0.905    331.699      0.000     298.257     301.807\n",
      "Private     -148.9186      0.413   -361.002      0.000    -149.728    -148.109\n",
      "==============================================================================\n",
      "Omnibus:                      621.633   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2006.696\n",
      "Skew:                           0.010   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.767   Cond. No.                         4.99\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "# 2. Analyze costs:\n",
    "#    - Simple analysis of insurance type effect\n",
    "#    - Box plots and basic statistics (report coeffcients and confidence intervals)\n",
    "#    - Calculate effect sizes\n",
    "\n",
    "# Convert insurance_type into dummy variables (one-hot encoding)\n",
    "X = pd.get_dummies(df['insurance_type'], drop_first=True)\n",
    "\n",
    "# Add 'visit_cost' as dependent variable\n",
    "y = df['visit_cost']\n",
    "\n",
    "# Add a constant to the model for intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(float)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "model_clustered = model.get_robustcov_results(cov_type='cluster', groups=df['patient_id'])\n",
    "\n",
    "# Display the summary of the regression\n",
    "print(model_clustered.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 198.98776897  -99.06586493  300.03181628 -148.9185683 ]\n",
      "[0. 0. 0. 0.]\n",
      "[[ 198.20094348  199.77459446]\n",
      " [ -99.92875253  -98.20297732]\n",
      " [ 298.25681718  301.80681538]\n",
      " [-149.72806156 -148.10907504]]\n",
      "0.96726176821306\n",
      "0.9672681333909836\n"
     ]
    }
   ],
   "source": [
    "print(model_clustered.params) # Coefficients \n",
    "print(model_clustered.pvalues) # P-values\n",
    "print(model_clustered.conf_int()) # Confidence Intervals\n",
    "print(model_clustered.rsquared_adj)\n",
    "print(model_clustered.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Advanced analysis:\n",
    "#    - Education age interaction effects on walking speed\n",
    "#    - Control for relevant confounders\n",
    "#    - Report key statistics and p-values (report coeffcients and confidence intervals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
